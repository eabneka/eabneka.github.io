---
title: "Q-Learning-APL"
categories:
  - APL
tags:
  - attempt
  - failed

toc: true
toc_sticky: true

---
**Warning :** Attempt failed. Detail description [here](#after-thoughts).
{: .notice--warning}
<a href="https://github.com/eabneka/q_learning_car" class="btn btn--success">Source Code</a>

## Production

### Concept

#### Environment



![simple](/assets/images/APL/IMG_0325.JPG)

### Explanation

Developed as three parts
- <a href="#car-operation">operation of car(direct control of motors)</a>
- inform that car is parked(terminal state)  
- Q-learning part 

#### car operation
<a href="https://github.com/eabneka/q_learning_car/blob/main/YB_Pcb_Car.py#L117">link to code line</a>

below method move the car.

```py
def Car_Action(self, act_num):
    if(act_num == 0):
    #forward
    elif(act_num == 1):
    #back
    elif(act_num == 2):
    #left
    elif(act_num == 3):
    #right
```
#### parked state

#### Q-learning

## After thoughts
### Why it failed
First, driving is contiunous action, which using q-table is doomed to fail. Second, car can't spin in place. Last, can't operate more than one car.

All of the above problems stem from Q-learning using q-table.
### Why, why it failed
> Should've focus on problem, not solution.

In other words, I was too exicted that i learned something, i've become somekind of zealot.

Such as "Q-learning is only and best solution, which can be applied to all problem!" or "Even considering another aproach is HERESY!" 


